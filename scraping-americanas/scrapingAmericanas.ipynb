{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install selenium\n",
    "from selenium import webdriver\n",
    "#pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "# tentando melhorar a questao dos bloqueios\n",
    "#pip install undetected-chromedriver==2.1.1   \n",
    "import undetected_chromedriver as uc \n",
    "from time import sleep\n",
    "import re\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array que vai conter todos os dados da pesquisa\n",
    "data = []\n",
    "americanasUrlBase = 'https://www.americanas.com.br'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configurando o webdrive\n",
    "options = webdriver.ChromeOptions() \n",
    "options.add_argument(\"start-maximized\")\n",
    "#o executable path está apenas com esse caminho porque se encontra na mesma pasta que o projeto\n",
    "# uma alternativa é colocar no path do sistema\n",
    "navegador = uc.Chrome(options=options, executable_path=r'../chromedriver.exe') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entra no site da americanas e navega até a primeira pagina de pesquisa da busca\n",
    "def gettingPageOne(search):\n",
    "    navegador.get(americanasUrlBase)\n",
    "    sleep(2)\n",
    "    barraPesquisa = navegador.find_element('xpath', '//*[@id=\"rsyswpsdk\"]/div/header/div[1]/div[1]/div/div[1]/form/input')\n",
    "    barraPesquisa.send_keys(search)\n",
    "    barraPesquisa.submit()\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettinData():\n",
    "    pagina = BeautifulSoup(navegador.page_source, 'html.parser') \n",
    "\n",
    "    # o findAll pega todos as divs que tenham a classe passada. perceba a importancia do uso do regex com o beatifulsoup\n",
    "    #  se você for no site da americanas e clicar em inspecionar elemento, vai ver que os produtos tem uma classe estranha\n",
    "    # mas que sempre mantem o padrão de inStockCard__Wrapper.\n",
    "    \n",
    "    allDivs = pagina.findAll('div',attrs={'class':re.compile('(inStockCard__Wrapper)')}) \n",
    "\n",
    "    #aqui eu pego dentro de todas as divs, as informaçoes que me interessam, perceba mais uma vez o uso do regex\n",
    "    for div in allDivs:\n",
    "        data.append({'name':div.find('h3', attrs={'class':re.compile('(product-name__Name)')}).text,\n",
    "        'price': div.find('span', attrs={'class':re.compile('(src__Text-sc)')}).text,\n",
    "        'link':americanasUrlBase+div.find('a').get('href')\n",
    "         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função responsavel por passar para a prox pagina\n",
    "def goNextPage():\n",
    "    try:\n",
    "        sleep(4)\n",
    "        # nao sei se por o botao de next está fora da tela ou o js dele nao ter renderizado, essa função da erro caso eu nao \n",
    "        #use o script para fazer a janela da scroll até o ponto onde ela é renderizada \n",
    "        navegador.execute_script(\"window.scrollTo(0, window.scrollY + 4400)\")\n",
    "        sleep(4)\n",
    "        buttonNext = navegador.find_element('xpath', '//*[@id=\"rsyswpsdk\"]/div/main/div/div[3]/div[3]/div/ul/li[10]')\n",
    "        #note que o selenium tenta simular um ser humano mexendo no navegador, se tiver algo na frente do botão como um popup \n",
    "        #impossibilitando o click manualmente, o selenium tbm nao vai conseguir clicar e dará um erro\n",
    "        buttonNext.click()\n",
    "        return True\n",
    "    except:\n",
    "        print('erro')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getscv(search): \n",
    "    header = ['name', 'price','link']\n",
    "    \n",
    "    with open('americanas'+search+'.csv', 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = header)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #o correto seria ao inves de fazer o print da data colocar em algo como um csv, mas já que esse nao é o foco fiquei com \n",
    "# #preguiça, dps faço\n",
    "# def SeeData():\n",
    "#     index = 1 # so pra eu saber a qtd de informaçoes que ele achou :)\n",
    "#     for dado in data:\n",
    "#         print(index)\n",
    "#         index+=1\n",
    "#         print('nome: ', dado['name'])\n",
    "#         print('preço: ', dado['price'])\n",
    "#         print('link: ', dado['link'])\n",
    "#         print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closePopup():\n",
    "    button =navegador.find_element('xpath', '//*[@id=\"rsyswpsdk\"]/div/header/div[2]/button')\n",
    "    button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que executa a busca \n",
    "from logging import NullHandler\n",
    "\n",
    "\n",
    "def searchAmericanas(search, numberPages):\n",
    "    page = 1\n",
    "    gettingPageOne(search)\n",
    "    try:\n",
    "        closePopup()\n",
    "    except:\n",
    "        NullHandler\n",
    "    while page <= numberPages:\n",
    "        gettinData()\n",
    "        goNext = goNextPage()\n",
    "        if(goNext):\n",
    "            page+=1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    navegador.close()\n",
    "    # SeeData()\n",
    "    getscv(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchAmericanas('televisao',3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
